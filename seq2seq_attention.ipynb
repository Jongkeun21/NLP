{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from pprint import pprint\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [['I', 'feel', 'hungry'],\n",
    "          ['tensorflow', 'is', 'very', 'difficult'],\n",
    "          ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "          ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "targets = [['나는', '배가', '고프다'],\n",
    "          ['텐서플로우는', '매우', '어렵다'],\n",
    "          ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
    "          ['텐서플로우는', '매우', '빠르게', '변화한다']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_vocab = list(set(sum(sources, [])))\n",
    "s_vocab.sort()\n",
    "s_vocab = ['<pad>'] + s_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source2idx = {word: idx for idx, word in enumerate(s_vocab)}\n",
    "idx2source = {idx: word for idx, word in enumerate(s_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0,\n",
      " 'I': 1,\n",
      " 'a': 2,\n",
      " 'changing': 3,\n",
      " 'deep': 4,\n",
      " 'difficult': 5,\n",
      " 'fast': 6,\n",
      " 'feel': 7,\n",
      " 'for': 8,\n",
      " 'framework': 9,\n",
      " 'hungry': 10,\n",
      " 'is': 11,\n",
      " 'learning': 12,\n",
      " 'tensorflow': 13,\n",
      " 'very': 14}\n"
     ]
    }
   ],
   "source": [
    "pprint(source2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>',\n",
      " 1: 'I',\n",
      " 2: 'a',\n",
      " 3: 'changing',\n",
      " 4: 'deep',\n",
      " 5: 'difficult',\n",
      " 6: 'fast',\n",
      " 7: 'feel',\n",
      " 8: 'for',\n",
      " 9: 'framework',\n",
      " 10: 'hungry',\n",
      " 11: 'is',\n",
      " 12: 'learning',\n",
      " 13: 'tensorflow',\n",
      " 14: 'very'}\n"
     ]
    }
   ],
   "source": [
    "pprint(idx2source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vocab = list(set(sum(targets, [])))\n",
    "t_vocab.sort()\n",
    "t_vocab = ['<pad>', '<bos>', '<eos>'] + t_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target2idx = {word: idx for idx, word in enumerate(t_vocab)}\n",
    "idx2target = {idx: word for idx, word in enumerate(t_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<bos>': 1,\n",
      " '<eos>': 2,\n",
      " '<pad>': 0,\n",
      " '고프다': 3,\n",
      " '나는': 4,\n",
      " '딥러닝을': 5,\n",
      " '매우': 6,\n",
      " '배가': 7,\n",
      " '변화한다': 8,\n",
      " '빠르게': 9,\n",
      " '어렵다': 10,\n",
      " '위한': 11,\n",
      " '텐서플로우는': 12,\n",
      " '프레임워크이다': 13}\n"
     ]
    }
   ],
   "source": [
    "pprint(target2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>',\n",
      " 1: '<bos>',\n",
      " 2: '<eos>',\n",
      " 3: '고프다',\n",
      " 4: '나는',\n",
      " 5: '딥러닝을',\n",
      " 6: '매우',\n",
      " 7: '배가',\n",
      " 8: '변화한다',\n",
      " 9: '빠르게',\n",
      " 10: '어렵다',\n",
      " 11: '위한',\n",
      " 12: '텐서플로우는',\n",
      " 13: '프레임워크이다'}\n"
     ]
    }
   ],
   "source": [
    "pprint(idx2target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sequences, max_len, dic, mode='source') :\n",
    "    assert mode in ['source', 'target'], 'source와 target 중에 선택해주세요.'\n",
    "    \n",
    "    if mode == 'source' :\n",
    "        #ENCODER\n",
    "        s_input = list(map(lambda sentence: [dic.get(token) for token in sentence], sequences))\n",
    "        s_len = list(map(lambda sentence: len(sentence), s_input))\n",
    "        s_input = pad_sequences(sequences=s_input, maxlen=max_len, padding='post', truncating='post')\n",
    "        \n",
    "        return s_len, s_input\n",
    "    \n",
    "    elif mode == 'target' :\n",
    "        #DECODER\n",
    "        t_input = list(map(lambda sentence: ['<bos>']+sentence+['<eos>'], sequences))\n",
    "        t_input = list(map(lambda sentence: [dic.get(token) for token in sentence], t_input))\n",
    "        t_len = list(map(lambda sentence: len(sentence), t_input))\n",
    "        t_input = pad_sequences(sequences=t_input, maxlen=max_len, padding='post', truncating='post')\n",
    "        \n",
    "        t_output = list(map(lambda sentence: sentence+['<eos>'], sequences))\n",
    "        t_output = list(map(lambda sentence: [dic.get(token) for token in sentence], t_output))\n",
    "        t_output = pad_sequences(sequences=t_output, maxlen=max_len, padding='post', truncating='post')\n",
    "        \n",
    "        return t_len, t_input, t_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_max_len = 10\n",
    "s_len, s_input = preprocess(sequences=sources, max_len=s_max_len, dic=source2idx, mode='source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 7, 5]\n",
      "array([[ 1,  7, 10,  0,  0,  0,  0,  0,  0,  0],\n",
      "       [13, 11, 14,  5,  0,  0,  0,  0,  0,  0],\n",
      "       [13, 11,  2,  9,  8,  4, 12,  0,  0,  0],\n",
      "       [13, 11, 14,  6,  3,  0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "pprint(s_len)\n",
    "pprint(s_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max_len = 12\n",
    "t_len, t_input, t_output = preprocess(sequences=targets, max_len=t_max_len, dic=target2idx, mode='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 6, 6]\n",
      "array([[ 1,  4,  7,  3,  2,  0,  0,  0,  0,  0,  0,  0],\n",
      "       [ 1, 12,  6, 10,  2,  0,  0,  0,  0,  0,  0,  0],\n",
      "       [ 1, 12,  5, 11, 13,  2,  0,  0,  0,  0,  0,  0],\n",
      "       [ 1, 12,  6,  9,  8,  2,  0,  0,  0,  0,  0,  0]])\n",
      "array([[ 4,  7,  3,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       [12,  6, 10,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       [12,  5, 11, 13,  2,  0,  0,  0,  0,  0,  0,  0],\n",
      "       [12,  6,  9,  8,  2,  0,  0,  0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "pprint(t_len)\n",
    "pprint(t_input)\n",
    "pprint(t_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 4\n",
    "learning_rate = 5e-3\n",
    "total_step = epochs/batch_size\n",
    "buffer_size = 100\n",
    "n_batch = buffer_size//batch_size\n",
    "embedding_dim = 32\n",
    "units = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
    "data = data.shuffle(buffer_size=buffer_size)\n",
    "data = data.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units) :\n",
    "    return tf.keras.layers.CuDNNGRU(units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model) :\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size) :\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden) :\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self) :\n",
    "        return tf.zeros((self.batch_size, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model) :\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_size) :\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        #used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output) :\n",
    "#         x = self.embedding(x)\n",
    "#         output, state = self.gru(x, initial_state=hidden)\n",
    "#         output = tf.reshape(output, (-1, output.shape[2]))\n",
    "#         x = self.fc(output)\n",
    "        \n",
    "#         return x, state\n",
    "\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        context_vector = attention_weights*enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "    \n",
    "    def initialize_hidden_state(self) :\n",
    "        return tf.zeros((self.batch_size, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Encoder object at 0x0000021283517DA0>\n",
      "<__main__.Decoder object at 0x0000021283517D30>\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
    "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)\n",
    "pprint(encoder)\n",
    "pprint(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred) :\n",
    "    mask = 1-np.equal(real, 0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0612 22:52:48.612856 21416 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = './data_out/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)\n",
    "\n",
    "summary_writer = tf.contrib.summary.create_file_writer(logdir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10,  Loss: 0.0378,  Batch Loss: 0.9448\n",
      "Epoch: 20,  Loss: 0.0344,  Batch Loss: 0.8605\n",
      "Epoch: 30,  Loss: 0.0328,  Batch Loss: 0.8207\n",
      "Epoch: 40,  Loss: 0.0304,  Batch Loss: 0.7592\n",
      "Epoch: 50,  Loss: 0.0261,  Batch Loss: 0.6521\n",
      "Epoch: 60,  Loss: 0.0183,  Batch Loss: 0.4579\n",
      "Epoch: 70,  Loss: 0.0119,  Batch Loss: 0.2979\n",
      "Epoch: 80,  Loss: 0.0074,  Batch Loss: 0.1849\n",
      "Epoch: 90,  Loss: 0.0046,  Batch Loss: 0.1141\n",
      "Epoch: 100,  Loss: 0.0029,  Batch Loss: 0.0716\n"
     ]
    }
   ],
   "source": [
    "result = float('inf')\n",
    "epoch = 0\n",
    "\n",
    "while result > 0.05 :\n",
    "    epoch += 1\n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data) :\n",
    "        loss = 0\n",
    "\n",
    "        with tf.GradientTape() as tape :\n",
    "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
    "            dec_hidden = enc_hidden\n",
    "            dec_input = tf.expand_dims([target2idx['<bos>']]*batch_size, 1)\n",
    "\n",
    "            for t in range(1, t_input.shape[1]) :\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                loss += loss_function(t_input[:, t], predictions)\n",
    "                dec_input = tf.expand_dims(t_input[:, t], 1)\n",
    "\n",
    "        batch_loss = (loss/int(t_input.shape[1]))\n",
    "        result = batch_loss.numpy()\n",
    "        total_loss += batch_loss\n",
    "        variables = encoder.variables+decoder.variables\n",
    "        gradient = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradient, variables))\n",
    "\n",
    "    if epoch%10 == 0 :\n",
    "        print('Epoch: {},  Loss: {:.4f},  Batch Loss: {:.4f}'.format(epoch, total_loss/n_batch, batch_loss.numpy()))\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x21280e6a630>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(sentence, encoder, decoder, inp_lang, tar_lang, max_length_inp, max_length_tar) :\n",
    "    result = ''\n",
    "    attention_plot = np.zeros((max_length_tar, max_length_inp))\n",
    "    \n",
    "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "        \n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([tar_lang['<bos>']], 0)\n",
    "    \n",
    "    for t in range(max_length_tar) :\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        result += idx2target[predicted_id]+' '\n",
    "        \n",
    "        if idx2target[predicted_id] == '<eos>' :\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence) :\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels(['']+sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels(['']+predicted_sentence, fontdict=fontdict)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, encoder, decoder, inp_lang, tar_lang, max_length_inp, max_length_tar) :\n",
    "    result, sentence, attention_plot = prediction(sentence, encoder, decoder, inp_lang, tar_lang, max_length_inp, max_length_tar)\n",
    "    \n",
    "    print(f\"Input: {sentence}\")\n",
    "    print(f\"Predicted: {result}\")\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'tensorflow is very difficult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensorflow is very difficult\n",
      "Predicted: 텐서플로우는 매우 어렵다 <eos> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
