{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['king is a strong man', \n",
    "          'queen is a wise woman', \n",
    "          'boy is a young man',\n",
    "          'girl is a young woman',\n",
    "          'prince is a young king',\n",
    "          'princess is a young queen',\n",
    "          'man is strong', \n",
    "          'woman is pretty',\n",
    "          'prince is a boy will be king',\n",
    "          'princess is a girl will be queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(corpus) :\n",
    "    stop_words = ['is', 'a', 'will', 'be']\n",
    "    results = []\n",
    "    \n",
    "    for text in corpus :\n",
    "        tmp = text.split(' ')\n",
    "        for stop_word in stop_words :\n",
    "            if stop_word in tmp :\n",
    "                tmp.remove(stop_word)\n",
    "        \n",
    "        results.append(\" \".join(tmp))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = remove_stop_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "for text in corpus :\n",
    "    for word in text.split(' ') :\n",
    "        words.append(word)\n",
    "words = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boy',\n",
       " 'girl',\n",
       " 'king',\n",
       " 'man',\n",
       " 'pretty',\n",
       " 'prince',\n",
       " 'princess',\n",
       " 'queen',\n",
       " 'strong',\n",
       " 'wise',\n",
       " 'woman',\n",
       " 'young'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "\n",
    "for i, word in enumerate(words) :\n",
    "    word2int[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for sentence in corpus :\n",
    "    sentences.append(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 2\n",
    "data = []\n",
    "\n",
    "for sentence in sentences :\n",
    "    for idx, word in enumerate(sentence) :\n",
    "#         print(\"idx: \", idx, \"  // word: \", word)\n",
    "        for neighbor in sentence[max(idx-WINDOW_SIZE, 0):min(idx+WINDOW_SIZE, len(sentence))+1] :\n",
    "            if neighbor != word :\n",
    "                data.append([word, neighbor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data, columns=['input', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "ONE_HOT_DIM = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot_encoding(data_point_index) :\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    \n",
    "    return one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(df['input'], df['label']) :\n",
    "    X.append(to_one_hot_encoding(word2int[x]))\n",
    "    Y.append(to_one_hot_encoding(word2int[y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([1]))\n",
    "hidden = tf.add(tf.matmul(x, W1), b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "pred = tf.nn.softmax(tf.add(tf.matmul(hidden, W2), b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y_))\n",
    "\n",
    "train = tf.train.AdamOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  2.470289\n",
      "loss:  2.271053\n",
      "loss:  2.2706945\n",
      "loss:  2.2700071\n",
      "loss:  2.2699394\n",
      "loss:  2.2699049\n",
      "loss:  2.2698846\n",
      "loss:  2.2698915\n",
      "loss:  2.2698653\n",
      "loss:  2.2891448\n",
      "loss:  2.2891307\n",
      "loss:  2.2891083\n",
      "loss:  2.2890902\n",
      "loss:  2.2891119\n",
      "loss:  2.3092802\n",
      "loss:  2.309257\n",
      "loss:  2.3092718\n",
      "loss:  2.309251\n",
      "loss:  2.3092666\n",
      "loss:  2.3092527\n",
      "loss:  2.3092515\n",
      "loss:  2.3092515\n",
      "loss:  2.309242\n",
      "loss:  2.3092413\n",
      "loss:  2.291681\n",
      "loss:  2.2708297\n",
      "loss:  2.2708127\n",
      "loss:  2.2707875\n",
      "loss:  2.2707808\n",
      "loss:  2.2707808\n",
      "loss:  2.269859\n",
      "loss:  2.2698681\n",
      "loss:  2.2698627\n",
      "loss:  2.269747\n",
      "loss:  2.3469815\n",
      "loss:  2.3469396\n",
      "loss:  2.3298147\n",
      "loss:  2.3297434\n",
      "loss:  2.3287072\n",
      "loss:  2.3289871\n",
      "loss:  2.3289924\n",
      "loss:  2.3100157\n",
      "loss:  2.3483236\n",
      "loss:  2.3482854\n",
      "loss:  2.3482966\n",
      "loss:  2.348218\n",
      "loss:  2.350011\n",
      "loss:  2.3530552\n",
      "loss:  2.3545375\n",
      "loss:  2.39302\n",
      "loss:  2.3930044\n",
      "loss:  2.3929923\n",
      "loss:  2.3737543\n",
      "loss:  2.3737426\n",
      "loss:  2.3743844\n",
      "loss:  2.3743894\n",
      "loss:  2.3743894\n",
      "loss:  2.3767905\n",
      "loss:  2.374959\n",
      "loss:  2.3721483\n",
      "loss:  2.3721385\n",
      "loss:  2.5120497\n",
      "loss:  2.512042\n",
      "loss:  2.4351227\n",
      "loss:  2.4351175\n",
      "loss:  2.3996997\n",
      "loss:  2.399704\n",
      "loss:  2.3997047\n",
      "loss:  2.3996942\n",
      "loss:  2.4023972\n",
      "loss:  2.4002028\n",
      "loss:  2.3996923\n",
      "loss:  2.3996916\n",
      "loss:  2.3996913\n",
      "loss:  2.4378195\n",
      "loss:  2.4378192\n",
      "loss:  2.4342725\n",
      "loss:  2.430874\n",
      "loss:  2.4308765\n",
      "loss:  2.4308736\n",
      "loss:  2.4153256\n",
      "loss:  2.415331\n",
      "loss:  2.4153247\n",
      "loss:  2.415325\n",
      "loss:  2.4137511\n",
      "loss:  2.4147296\n",
      "loss:  2.4147284\n",
      "loss:  2.3955183\n",
      "loss:  2.3954961\n",
      "loss:  2.3954935\n",
      "loss:  2.3954928\n",
      "loss:  2.3966966\n",
      "loss:  2.3966956\n",
      "loss:  2.3966951\n",
      "loss:  2.3971825\n",
      "loss:  2.3966942\n",
      "loss:  2.3966954\n",
      "loss:  2.3994014\n",
      "loss:  2.3994014\n",
      "loss:  2.3994014\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "_iter = 200000\n",
    "for i in range(_iter) :\n",
    "    _, _loss = sess.run([train, loss], feed_dict={x: X_train, y_: Y_train})\n",
    "    if i % 2000 == 0 :\n",
    "        print(\"loss: \", _loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.1818600e+00 -5.4658031e+01]\n",
      " [-4.0894375e+00 -1.4643934e+01]\n",
      " [-3.8933933e+01  2.3771036e+01]\n",
      " [-2.0366446e+01 -3.9570908e+01]\n",
      " [ 9.6982117e+00 -8.8899612e-02]\n",
      " [-2.0779226e+01 -3.9444889e+01]\n",
      " [-8.1696615e+00 -4.2788994e+01]\n",
      " [-4.0750629e+01 -1.3267050e+01]\n",
      " [-4.6972752e-02 -1.3757801e-01]\n",
      " [-2.5483156e+01 -4.3898285e+01]\n",
      " [-8.0245552e+00 -4.2239044e+01]\n",
      " [-2.0438652e+01 -3.9939075e+01]]\n"
     ]
    }
   ],
   "source": [
    "vectors = sess.run(W1+b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretty</td>\n",
       "      <td>9.181860</td>\n",
       "      <td>-54.658031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>man</td>\n",
       "      <td>-4.089437</td>\n",
       "      <td>-14.643934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>queen</td>\n",
       "      <td>-38.933933</td>\n",
       "      <td>23.771036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>princess</td>\n",
       "      <td>-20.366446</td>\n",
       "      <td>-39.570908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>woman</td>\n",
       "      <td>9.698212</td>\n",
       "      <td>-0.088900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>girl</td>\n",
       "      <td>-20.779226</td>\n",
       "      <td>-39.444889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prince</td>\n",
       "      <td>-8.169662</td>\n",
       "      <td>-42.788994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>strong</td>\n",
       "      <td>-40.750629</td>\n",
       "      <td>-13.267050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>young</td>\n",
       "      <td>-0.046973</td>\n",
       "      <td>-0.137578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>king</td>\n",
       "      <td>-25.483156</td>\n",
       "      <td>-43.898285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>boy</td>\n",
       "      <td>-8.024555</td>\n",
       "      <td>-42.239044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wise</td>\n",
       "      <td>-20.438652</td>\n",
       "      <td>-39.939075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word         x1         x2\n",
       "0     pretty   9.181860 -54.658031\n",
       "1        man  -4.089437 -14.643934\n",
       "2      queen -38.933933  23.771036\n",
       "3   princess -20.366446 -39.570908\n",
       "4      woman   9.698212  -0.088900\n",
       "5       girl -20.779226 -39.444889\n",
       "6     prince  -8.169662 -42.788994\n",
       "7     strong -40.750629 -13.267050\n",
       "8      young  -0.046973  -0.137578\n",
       "9       king -25.483156 -43.898285\n",
       "10       boy  -8.024555 -42.239044\n",
       "11      wise -20.438652 -39.939075"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df = pd.DataFrame(vectors, columns=['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']) :\n",
    "    ax.annotate(word, (x1, x2))\n",
    "    \n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    " \n",
    "plt.xlim(x_axis_min,x_axis_max)\n",
    "plt.ylim(y_axis_min,y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
